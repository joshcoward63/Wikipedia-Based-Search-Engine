{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pediatric-buyer",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import string\n",
    "import json\n",
    "from os.path import exists\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-indiana",
   "metadata": {},
   "source": [
    "### Preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing preproccesing tools and a empty dictionary to store processed data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(\".\")\n",
    "stop_words.add(\",\")\n",
    "processed_collection = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-morocco",
   "metadata": {},
   "source": [
    "## Load in Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_read = open(\"inverted_index\", \"rb\")\n",
    "inverted_index = pickle.load(file_to_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-enzyme",
   "metadata": {},
   "source": [
    "## Load in Wiki sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Josh\\\\Downloads\\\\project_1_Wiki_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-parks",
   "metadata": {},
   "source": [
    "## Load in AOL Query Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"C:\\\\Users\\\\Josh\\\\Desktop\\\\cs437p1\\\\project_1_AOL_query_log\\\\Clean-Data-01.txt\",sep='\\t')\n",
    "df2 = df2.append(pd.read_csv(\"C:\\\\Users\\\\Josh\\\\Desktop\\\\cs437p1\\\\project_1_AOL_query_log\\\\Clean-Data-02.txt\",sep='\\t'))\n",
    "df2 = df2.append(pd.read_csv(\"C:\\\\Users\\\\Josh\\\\Desktop\\\\cs437p1\\\\project_1_AOL_query_log\\\\Clean-Data-03.txt\",sep='\\t'))\n",
    "df2 = df2.append(pd.read_csv(\"C:\\\\Users\\\\Josh\\\\Desktop\\\\cs437p1\\\\project_1_AOL_query_log\\\\Clean-Data-04.txt\",sep='\\t'))\n",
    "df2 = df2.append(pd.read_csv(\"C:\\\\Users\\\\Josh\\\\Desktop\\\\cs437p1\\\\project_1_AOL_query_log\\\\Clean-Data-05.txt\",sep='\\t'))\n",
    "df2[\"Query\"] = df2[\"Query\"].astype(str)\n",
    "df2[\"QueryTime\"]= pd.to_datetime(df2[\"QueryTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(query, tfidf):\n",
    "    query = [lemmatizer.lemmatize(x.lower()) for x  in word_tokenize(query)]\n",
    "    list_of_documents = []\n",
    "    for token in query:\n",
    "        if token in tfidf.keys():\n",
    "            list_of_documents.append(set(tfidf[token]))\n",
    "#     list_of_documents = set(itertools.chain.from_iterable(list_of_documents))\n",
    "    list_of_documents = list(set.intersection(*map(set,list_of_documents)))\n",
    "    \n",
    "    unchecked_tokens = query\n",
    "    while len(list_of_documents) < 6 and not(len(unchecked_tokens) == 0):\n",
    "        d = {}\n",
    "        for token in unchecked_tokens:\n",
    "            d[token] = len(tfidf[token])\n",
    "        lowest = min(d, key=d.get)\n",
    "        unchecked_tokens.pop(list(d.keys()).index(lowest))\n",
    "        list_of_documents = list(set(list_of_documents).union(set(tfidf[lowest])))\n",
    "    return list_of_documents, query    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(clean_query, list_of_cannidates, tfidf):\n",
    "    total_num_of_docs = len(df)\n",
    "    term_probs = {}\n",
    "    for doc in list_of_cannidates:\n",
    "        term_probs[doc] = 1\n",
    "        for term in clean_query:\n",
    "            temp_list = [lemmatizer.lemmatize(x.lower()) for x in word_tokenize(df['content'][doc-1])]\n",
    "            if temp_list.count(term) == 0:\n",
    "                term_probs[doc] = term_probs[doc] * 0.00001 * ((0.00001) / total_num_of_docs)\n",
    "            else:\n",
    "                term_probs[doc] = term_probs[doc] * (temp_list.count(term) / len(temp_list)) * (len(tfidf[term]) / total_num_of_docs) \n",
    "    return term_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-spell",
   "metadata": {},
   "source": [
    "## Load Flask library and needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-guatemala",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template,request, redirect, request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-short",
   "metadata": {},
   "source": [
    "## The search-engine app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route('/ajax', methods = ['POST'])\n",
    "def returnHome():\n",
    "    print(\"homeeee\")\n",
    "    return redirect(\"index.html\")\n",
    "\n",
    "@app.route('/suggest', methods = ['POST'])\n",
    "def suggest():\n",
    "    \"\"\"Returns new df with queries that start with the query parameter. Sorted by frequency, excludes exact match.\"\"\"\n",
    "    query = request.form['myQuery']\n",
    "    sg = df2.loc[df2['Query'].str.startswith(query)]\n",
    "    sg = sg[sg['Query'] != query]\n",
    "    sg = sg.groupby(['Query']).size().reset_index(name='freq')\n",
    "    sg = sg.sort_values(by=['freq'],ascending=False)\n",
    "    data_dict = sg.head(5).to_dict()\n",
    "    return data_dict['Query']\n",
    "\n",
    "def build_results(data):\n",
    "    sorted_dict = dict(sorted(data.items(), key=lambda item: item[1], reverse=True))\n",
    "    results = {}\n",
    "    for key in sorted_dict:\n",
    "        results[key] = {\"content\":df['content'][key-1], \"title\":df['title'][key-1]}\n",
    "    return results\n",
    "\n",
    "@app.route('/results')\n",
    "def results(query):\n",
    "    print(\"resultsss\", query)\n",
    "    list_of_cannidates, clean_query = getResults(query,inverted_index)\n",
    "    unsorted_dictionary_of_doc_probs = ranking(clean_query, list_of_cannidates, inverted_index)\n",
    "    results = build_results(unsorted_dictionary_of_doc_probs)\n",
    "    return render_template(\"results.html\", query=clean_query, results = results, number_of_results = len(results))\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def getQuery():\n",
    "    query = request.form['myQuery']\n",
    "    return results(query)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=5505)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
